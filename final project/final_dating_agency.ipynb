{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System For Dating Agency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users of online dating sites are facing information overload that requires them to manually construct queries and browse huge amount of matching user profiles. A typical dating site requires users to fill in lengthy questionnaires and matching is based on attributes selected. The search in the database either returns no match in the case when the query is too specific or, for general queries, returns a huge amount of profiles. In the end users end up browsing large amount of irrelevant results. Building a recommender system can help to improve user experience of dating site users and lead to a higher user satisfaction by making the process of finding a relevant candidate quicker and more efficient.\n",
    "\n",
    "The purpose of this project is to develop a recommender system using collaborative filtering algorithms (user- and item-based) walking though the following steps:\n",
    "\n",
    "1. Data Exploration\n",
    "2. User-Based Collaborative Filtering (top N recommendations)\n",
    "3. Item-Based Collaborative Filtering (top N recommendations)\n",
    "4. KNN Recommender Algorithms. Selecting the best system based on the RMSE using cross validation.\n",
    "5. Measuring Coverage and Diversity of the selected KNN-Recommender Algorithm.\n",
    "6. Implementation SVD method and tuning it selecting best parameter using RMSE.\n",
    "\n",
    "Core ML package that will be used throughout the project is Surprise - Python scikit building and analyzing recommender systems library.\n",
    "\n",
    "Data Source: http://www.occamslab.com/petricek/data/\n",
    "\n",
    "This data set contains 168,791 profiles and presented in the following format:\n",
    "\n",
    "UserID is user who provided rating\n",
    "ProfileID is user who has been rated\n",
    "UserIDs range between 1 and 135,359\n",
    "ProfileIDs range between 1 and 220,970 (not every profile has been rated).\n",
    "Ratings are on a 1-10 scale where 10 is best (integer ratings only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import KNNBaseline, KNNWithZScore, NormalPredictor, KNNWithMeans, BaselineOnly, SVD, KNNBasic, SlopeOne, NMF, CoClustering\n",
    "\n",
    "# import heapq\n",
    "import random \n",
    "import numpy as np\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>candidateID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>971</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1095</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1616</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  candidateID  rating\n",
       "0       1          133       8\n",
       "1       1          720       6\n",
       "2       1          971      10\n",
       "3       1         1095       7\n",
       "4       1         1616      10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading file into a pandas data frame\n",
    "data = pd.read_csv('/Users/Olga/PycharmProjects/rec_sys_final/ratings.csv', header=None)\n",
    "data.columns = [\"userID\", \"candidateID\", \"rating\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    3540342\n",
       "9     1117416\n",
       "8     1664057\n",
       "7     1793187\n",
       "6     1605496\n",
       "5     1991628\n",
       "4     1096031\n",
       "3     1000377\n",
       "2     1235266\n",
       "1     2315546\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  rating distribution\n",
    "data.rating.value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rating distribution (graph)\n",
    "data.rating.value_counts().sort_index(ascending=False).plot(kind='bar')\n",
    "plt.title('Rating Distribution')\n",
    "plt.ylabel('Number Of Users')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 is the most popular rating.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidateID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103968</th>\n",
       "      <td>156148</td>\n",
       "      <td>33389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19179</th>\n",
       "      <td>31116</td>\n",
       "      <td>28398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141507</th>\n",
       "      <td>193687</td>\n",
       "      <td>23649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74939</th>\n",
       "      <td>121859</td>\n",
       "      <td>23639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51440</th>\n",
       "      <td>83773</td>\n",
       "      <td>23113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13725</th>\n",
       "      <td>22319</td>\n",
       "      <td>21387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43941</th>\n",
       "      <td>71636</td>\n",
       "      <td>21284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55190</th>\n",
       "      <td>89855</td>\n",
       "      <td>20634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12749</th>\n",
       "      <td>20737</td>\n",
       "      <td>18550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110527</th>\n",
       "      <td>162707</td>\n",
       "      <td>18224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        candidateID  rating\n",
       "103968       156148   33389\n",
       "19179         31116   28398\n",
       "141507       193687   23649\n",
       "74939        121859   23639\n",
       "51440         83773   23113\n",
       "13725         22319   21387\n",
       "43941         71636   21284\n",
       "55190         89855   20634\n",
       "12749         20737   18550\n",
       "110527       162707   18224"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of ratings per each candidate\n",
    "data.groupby('candidateID')['rating'].count().reset_index().sort_values('rating', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-Based (top N recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first algorithm that will be built is user-based collaborative filtering. I will take the \"test user\" (for example,10th user) and find the top 10 candidates for the \"test user\" via following steps:\n",
    "\n",
    "1. Candidate generation step when we pull all the candidates in from every neighbor of the selected \"test user\". Neighbours for the \"test user\" is selected based on the similarity measure.\n",
    "\n",
    "2. Candidate scoring allows to select the best candidates for the \"test user\". I will weigh ratings by users similarity.\n",
    "\n",
    "3. Sorting the candidates by their final score.\n",
    "\n",
    "4. Candidates filtering where I filter out candidates which the \"test user\" has already rated. Also I will apply filter on the min candidate score or min similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading csv file\n",
    "reader = Reader(sep=',', rating_scale=(1, 10))\n",
    "data = Dataset.load_from_file(\"/Users/Olga/PycharmProjects/rec_sys_final/ratings_short.csv\", reader=reader)\n",
    "\n",
    "# splitting data set on train and test\n",
    "trainSet, testSet = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "#  assigning similarity measure options\n",
    "sim_options = {'name': 'cosine', 'user_based': True}\n",
    "\n",
    "#  computing user to user similarity matrix using KNNBasic algorithm\n",
    "model_1 = KNNBasic(sim_options = sim_options)\n",
    "model_1.fit(trainSet)\n",
    "simMatrix = model_1.compute_similarities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33216 3.8\n",
      "113157 3.0\n",
      "2111 2.4000000000000004\n",
      "22327 2.3\n",
      "45385 2.0\n",
      "175806 2.0\n",
      "71570 2.0\n",
      "30166 2.0\n",
      "32694 2.0\n",
      "11265 1.5\n"
     ]
    }
   ],
   "source": [
    "# selecting test user - for example, 10th user\n",
    "testUser = '10'\n",
    "\n",
    "# extracting similar users to our test user\n",
    "testUserInnerID = trainSet.to_inner_uid(testUser)\n",
    "similarityRow = simMatrix[testUserInnerID]\n",
    "\n",
    "# converting these users to the list of tuples containing inner user Id and similarity score (skipping the test user similarity to him/herself)\n",
    "similarUsers = []\n",
    "for innerID, score in enumerate(similarityRow):\n",
    "    if (innerID != testUserInnerID):\n",
    "        similarUsers.append( (innerID, score) )\n",
    "        \n",
    "#  filtering out users with similarity score to the test user less than 0.95   \n",
    "kNeighbors = []\n",
    "for rating in similarUsers:\n",
    "    if rating[1] > 0.95:\n",
    "        kNeighbors.append(rating)\n",
    "\n",
    "# getting the candidates the users have rated, and adding up ratings for each candidate, weighted by user similarity\n",
    "candidates = defaultdict(float)\n",
    "for similarUser in kNeighbors:\n",
    "    innerID = similarUser[0]\n",
    "    userSimilarityScore = similarUser[1]\n",
    "    theirRatings = trainSet.ur[innerID]\n",
    "    for rating in theirRatings:\n",
    "        candidates[rating[0]] += (rating[1]/10.0) * userSimilarityScore\n",
    "\n",
    "# Building a dictionary of candidates that the test user has already rated\n",
    "rated = {}\n",
    "for candidateID, rating in trainSet.ur[testUserInnerID]:\n",
    "    rated[candidateID] = 1\n",
    "\n",
    "# getting 10 top-rated candidates for the test user:\n",
    "n = 10\n",
    "pos = 1\n",
    "# sorting the candidates by the final score and selecting top 10 skipping the results that the test user has already rated.\n",
    "for candidateID, ratingSum in sorted(candidates.items(), key=itemgetter(1), reverse=True):\n",
    "    if not candidateID in rated:\n",
    "        candidateID = trainSet.to_raw_iid(candidateID)\n",
    "#       printing candidates IDs for 10th test user \n",
    "        print(candidateID, ratingSum)\n",
    "        pos += 1\n",
    "        if (pos > n):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-Based (top N recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Next algorithm that I am going to implement is item-based. I will take the same \"test user\" (10th user) and find the top 10 candidates for the \"test user\" using item-based collaborative filtering.\n",
    "Item similarities can be better then similarities between users because items tend to have more permanent nature, unlike users' tastes. That's why focusing on the similarities between unchanging objects may produce better results.\n",
    "The algorithms for item-based recommendations is quite similar to user - based, we are just focusing on the relations between items instead of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "#  assigning similarity measure options\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': False\n",
    "               }\n",
    "\n",
    "#  computing candidate to candidate similarity matrix \n",
    "model = KNNBasic(sim_options=sim_options)\n",
    "model.fit(trainSet)\n",
    "simsMatrix = model.compute_similarities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198157 0.9\n",
      "36711 0.9\n",
      "101318 0.9\n",
      "96603 0.9\n",
      "52701 0.9\n",
      "18719 0.9\n",
      "50148 0.9\n",
      "76467 0.9\n",
      "117720 0.9\n",
      "25850 0.9\n"
     ]
    }
   ],
   "source": [
    "# selecting test user - for example, 10th user\n",
    "testUser = '10'\n",
    "\n",
    "# converting a user raw id to an inner id\n",
    "testUserInnerID = trainSet.to_inner_uid(testUser)\n",
    "# extracting similar candidates to the candidates the test user prefer\n",
    "testUserRatings = trainSet.ur[testUserInnerID]\n",
    "\n",
    "# filtering out candidates with rating less then 8\n",
    "kNeighbors = []\n",
    "for rating in testUserRatings:\n",
    "    if rating[1] > 8.0:\n",
    "        kNeighbors.append(rating)\n",
    "        \n",
    "\n",
    "# getting the candidates and adding up ratings for each candidate, weighted by similarity score\n",
    "candidates = defaultdict(float)\n",
    "for candidateID, rating in kNeighbors:\n",
    "    similarityRow = simsMatrix[candidateID]\n",
    "    for innerID, score in enumerate(similarityRow):\n",
    "        candidates[innerID] += score * (rating)/10.0\n",
    "    \n",
    "# building a dictionary of candidates that the test user has already seen\n",
    "rated = {}\n",
    "for candidateID, rating in trainSet.ur[testUserInnerID]:\n",
    "    rated[candidateID] = 1\n",
    "    \n",
    "# getting 10 top-rated candidated for the test user:\n",
    "n = 10\n",
    "pos = 1\n",
    "for candidateID, ratingSum in sorted(candidates.items(), key=itemgetter(1), reverse=True):\n",
    "    if not candidateID in rated:\n",
    "        candidateID = trainSet.to_raw_iid(candidateID)\n",
    "        print(candidateID, ratingSum)\n",
    "        pos += 1\n",
    "        if (pos > n):\n",
    "            break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User-based and item-based algorithms produced quite different recommendations for the 10th user. It is hard to tell if they are good or bad. I can not measure accuracy for the User-based and item-based algorithms produced above as it is not rating prediction methods which I will consider further. Also it is quite hard to judge intuitively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Recommender Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept of collaborative filtering has been applied to recommender systems that make rating predictions and this is called KNN recommenders.\n",
    "In KNN recommender systems we are generating recommendation candidates by predicting their rating and selecting top K candidates with the highest predicted rating. Since we are using ratings prediction we can measure system accuracy via train/test split or cross-validation. \n",
    "\n",
    "KNN recommenders are not just recommending candidates that people similar to the selected user like, but also they are trying to predict rating for every possible candidate for every possible user. \n",
    "\n",
    "The following basics algorithms will be benchmarked in order to select the best one:\n",
    "\n",
    "    - NormalPredictor algorithm predicts a random rating based on the distribution of the training set, which is assumed to be normal.\n",
    "    - KNNBaseline is a basic collaborative filtering algorithm taking into account a baseline rating.\n",
    "    - KNNBasic is a basic collaborative filtering algorithm.\n",
    "    - KNNWithMeans is basic collaborative filtering algorithm, taking into account the mean ratings of each user.\n",
    "    - KNNWithZScore is a basic collaborative filtering algorithm, taking into account the z-score normalization of each user.\n",
    "    - BaselineOnly is a basic collaborative filtering algorithm taking into account a baseline rating.\n",
    "    - SVD is a method that utilizes matrix factorization technique.\n",
    "    \n",
    "Some of these algorithms use baseline estimates, some use a similarity measures.  \n",
    "These algorithms will be tested using user- and item-based approach with cosine or pearson similarity measure. Cross-validation will be applied to measure algorithms accuracy via RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>2.826019</td>\n",
       "      <td>0.019879</td>\n",
       "      <td>0.024740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>2.871684</td>\n",
       "      <td>0.018075</td>\n",
       "      <td>0.017112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>2.872767</td>\n",
       "      <td>0.408892</td>\n",
       "      <td>0.021322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>2.973191</td>\n",
       "      <td>0.004910</td>\n",
       "      <td>0.037630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>2.986532</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.026498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>2.992198</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>0.036641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>4.078426</td>\n",
       "      <td>0.007736</td>\n",
       "      <td>0.020568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_rmse  fit_time  test_time\n",
       "Algorithm                                      \n",
       "KNNBaseline       2.826019  0.019879   0.024740\n",
       "BaselineOnly      2.871684  0.018075   0.017112\n",
       "SVD               2.872767  0.408892   0.021322\n",
       "KNNWithMeans      2.973191  0.004910   0.037630\n",
       "KNNWithZScore     2.986532  0.008571   0.026498\n",
       "KNNBasic          2.992198  0.002543   0.036641\n",
       "NormalPredictor   4.078426  0.007736   0.020568"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark = []\n",
    "sim_options = {'name': 'cosine', 'user_based': True}\n",
    "# iterating over all algorithms\n",
    "for algorithm in [SVD(), NormalPredictor(), KNNBaseline(sim_options=sim_options), KNNBasic(sim_options=sim_options), KNNWithMeans(sim_options=sim_options), KNNWithZScore(sim_options=sim_options), BaselineOnly()]:\n",
    "    # performing 3 fold cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "    \n",
    "    # getting results & appending algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    \n",
    "pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>2.840108</td>\n",
       "      <td>0.022661</td>\n",
       "      <td>0.027093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>2.867458</td>\n",
       "      <td>0.021198</td>\n",
       "      <td>0.017427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>2.875594</td>\n",
       "      <td>0.417361</td>\n",
       "      <td>0.020836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>2.986687</td>\n",
       "      <td>0.008138</td>\n",
       "      <td>0.024218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>2.997407</td>\n",
       "      <td>0.004735</td>\n",
       "      <td>0.023885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>3.022165</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>0.024274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>4.088883</td>\n",
       "      <td>0.008090</td>\n",
       "      <td>0.020555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_rmse  fit_time  test_time\n",
       "Algorithm                                      \n",
       "KNNBaseline       2.840108  0.022661   0.027093\n",
       "BaselineOnly      2.867458  0.021198   0.017427\n",
       "SVD               2.875594  0.417361   0.020836\n",
       "KNNWithZScore     2.986687  0.008138   0.024218\n",
       "KNNWithMeans      2.997407  0.004735   0.023885\n",
       "KNNBasic          3.022165  0.003023   0.024274\n",
       "NormalPredictor   4.088883  0.008090   0.020555"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark = []\n",
    "sim_options = {'name': 'pearson', 'user_based': True}\n",
    "# iterating over all algorithms\n",
    "for algorithm in [SVD(), NormalPredictor(), KNNBaseline(sim_options=sim_options), KNNBasic(sim_options=sim_options), KNNWithMeans(sim_options=sim_options), KNNWithZScore(sim_options=sim_options), BaselineOnly()]:\n",
    "    # performing 3 fold cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "    \n",
    "    # getting results & appending algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    \n",
    "pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>2.867220</td>\n",
       "      <td>0.023051</td>\n",
       "      <td>0.018684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>2.868909</td>\n",
       "      <td>0.424588</td>\n",
       "      <td>0.020370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>2.890424</td>\n",
       "      <td>4.501214</td>\n",
       "      <td>0.224689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>2.968432</td>\n",
       "      <td>4.473096</td>\n",
       "      <td>0.181216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>3.004862</td>\n",
       "      <td>4.630617</td>\n",
       "      <td>0.183989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>3.084678</td>\n",
       "      <td>4.420549</td>\n",
       "      <td>0.177156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>4.106802</td>\n",
       "      <td>0.008332</td>\n",
       "      <td>0.021000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_rmse  fit_time  test_time\n",
       "Algorithm                                      \n",
       "BaselineOnly      2.867220  0.023051   0.018684\n",
       "SVD               2.868909  0.424588   0.020370\n",
       "KNNBaseline       2.890424  4.501214   0.224689\n",
       "KNNWithMeans      2.968432  4.473096   0.181216\n",
       "KNNWithZScore     3.004862  4.630617   0.183989\n",
       "KNNBasic          3.084678  4.420549   0.177156\n",
       "NormalPredictor   4.106802  0.008332   0.021000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark = []\n",
    "sim_options = {'name': 'cosine', 'user_based': False}\n",
    "# iterating over all algorithms\n",
    "for algorithm in [SVD(), NormalPredictor(), KNNBaseline(sim_options=sim_options), KNNBasic(sim_options=sim_options), KNNWithMeans(sim_options=sim_options), KNNWithZScore(sim_options=sim_options), BaselineOnly()]:\n",
    "    # performing 3 fold cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "    \n",
    "    # getting results & appending algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    \n",
    "pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>2.869778</td>\n",
       "      <td>0.417611</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>2.873733</td>\n",
       "      <td>5.997423</td>\n",
       "      <td>0.187015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>2.874607</td>\n",
       "      <td>0.020333</td>\n",
       "      <td>0.018537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>2.991830</td>\n",
       "      <td>5.915933</td>\n",
       "      <td>0.177267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>2.997933</td>\n",
       "      <td>5.906449</td>\n",
       "      <td>0.174891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>3.097986</td>\n",
       "      <td>5.830549</td>\n",
       "      <td>0.192854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>4.090151</td>\n",
       "      <td>0.008380</td>\n",
       "      <td>0.020732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_rmse  fit_time  test_time\n",
       "Algorithm                                      \n",
       "SVD               2.869778  0.417611   0.020833\n",
       "KNNBaseline       2.873733  5.997423   0.187015\n",
       "BaselineOnly      2.874607  0.020333   0.018537\n",
       "KNNWithZScore     2.991830  5.915933   0.177267\n",
       "KNNWithMeans      2.997933  5.906449   0.174891\n",
       "KNNBasic          3.097986  5.830549   0.192854\n",
       "NormalPredictor   4.090151  0.008380   0.020732"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark = []\n",
    "sim_options = {'name': 'pearson', 'user_based': False}\n",
    "# iterating over all algorithms\n",
    "for algorithm in [SVD(), NormalPredictor(), KNNBaseline(sim_options=sim_options), KNNBasic(sim_options=sim_options), KNNWithMeans(sim_options=sim_options), KNNWithZScore(sim_options=sim_options), BaselineOnly()]:\n",
    "    # performing 3 fold cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "    \n",
    "    # getting results & appending algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    \n",
    "pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most accurate result produces KNNBaseline, the worst - NormalPredictor, although it is the fastest algorithm. I am going to train and predict with KNNBaseline method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 2.8892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.8892035526873827"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  splitting data on train and test set\n",
    "trainSet, testSet = train_test_split(data, test_size=.15)\n",
    "# selecting similarity options which gave the best result during cross-validation: user-based and pearson.\n",
    "sim_options = {'name': 'pearson', 'user_based': True}\n",
    "#  building the model\n",
    "algo = KNNBaseline(sim_options = sim_options)\n",
    "model = algo.fit(trainSet)\n",
    "#  making predictions\n",
    "predictions = model.test(testSet)\n",
    "# calculating RMSE\n",
    "accuracy.rmse(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://nbviewer.jupyter.org/github/NicolasHug/Surprise/blob/master/examples/notebooks/KNNBasic_analysis.ipynb\n",
    "# selecting top 10 best and worst predictions.\n",
    "def get_Iu(uid):\n",
    "    \"\"\" return the number of items rated by given user\n",
    "    args: \n",
    "      uid: the id of the user\n",
    "    returns: \n",
    "      the number of items rated by the user\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return len(trainSet.ur[trainSet.to_inner_uid(uid)])\n",
    "    except ValueError: # user was not part of the trainSet\n",
    "        return 0\n",
    "    \n",
    "def get_Ui(iid):\n",
    "    \"\"\" return number of users that have rated given item\n",
    "    args:\n",
    "      iid: the raw id of the item\n",
    "    returns:\n",
    "      the number of users that have rated the item.\n",
    "    \"\"\"\n",
    "    try: \n",
    "        return len(trainSet.ir[trainSet.to_inner_iid(iid)])\n",
    "    except ValueError:\n",
    "        return 0\n",
    "    \n",
    "df = pd.DataFrame(predictions, columns=['uid', 'iid', 'rui', 'est', 'details'])\n",
    "df['Iu'] = df.uid.apply(get_Iu)\n",
    "df['Ui'] = df.iid.apply(get_Ui)\n",
    "df['err'] = abs(df.est - df.rui)\n",
    "best_predictions = df.sort_values(by='err')[:10]\n",
    "worst_predictions = df.sort_values(by='err')[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     uid     iid   rui   est                                   details   Iu  \\\n",
      "368   40   16860  10.0  10.0  {'actual_k': 1, 'was_impossible': False}  105   \n",
      "1471  13  109694  10.0  10.0  {'actual_k': 1, 'was_impossible': False}   16   \n",
      "860   31   76965  10.0  10.0  {'actual_k': 1, 'was_impossible': False}  350   \n",
      "482   57  120597  10.0  10.0  {'actual_k': 1, 'was_impossible': False}   81   \n",
      "726   38  120849  10.0  10.0  {'actual_k': 1, 'was_impossible': False}  183   \n",
      "848   38   14873  10.0  10.0  {'actual_k': 1, 'was_impossible': False}  183   \n",
      "214   71  130970  10.0  10.0  {'actual_k': 3, 'was_impossible': False}   53   \n",
      "1218  18  122024   1.0   1.0  {'actual_k': 1, 'was_impossible': False}  218   \n",
      "203   18  128292   1.0   1.0  {'actual_k': 1, 'was_impossible': False}  218   \n",
      "1280   4   65602  10.0  10.0  {'actual_k': 2, 'was_impossible': False}   83   \n",
      "\n",
      "      Ui  err  \n",
      "368    1  0.0  \n",
      "1471   1  0.0  \n",
      "860    1  0.0  \n",
      "482    1  0.0  \n",
      "726    1  0.0  \n",
      "848    1  0.0  \n",
      "214    5  0.0  \n",
      "1218   1  0.0  \n",
      "203    1  0.0  \n",
      "1280   4  0.0  \n"
     ]
    }
   ],
   "source": [
    "print(best_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     uid     iid   rui        est                                   details  \\\n",
      "314   31  132086   1.0   8.089274                 {'was_impossible': False}   \n",
      "485   31   34502   1.0   8.089274                 {'was_impossible': False}   \n",
      "820   31  137591   1.0   8.089274                 {'was_impossible': False}   \n",
      "1020  18   53364   1.0   8.590643  {'actual_k': 1, 'was_impossible': False}   \n",
      "306   38  196134   1.0   8.668751                 {'was_impossible': False}   \n",
      "126   38   86320   1.0   8.668751                 {'was_impossible': False}   \n",
      "1259  45  112662  10.0   1.409756  {'actual_k': 1, 'was_impossible': False}   \n",
      "264   47   70269   1.0   9.850217  {'actual_k': 1, 'was_impossible': False}   \n",
      "147   31   54775   1.0  10.000000  {'actual_k': 2, 'was_impossible': False}   \n",
      "1463  70  212147   1.0  10.000000  {'actual_k': 1, 'was_impossible': False}   \n",
      "\n",
      "       Iu  Ui       err  \n",
      "314   350   0  7.089274  \n",
      "485   350   0  7.089274  \n",
      "820   350   0  7.089274  \n",
      "1020  218   1  7.590643  \n",
      "306   183   0  7.668751  \n",
      "126   183   0  7.668751  \n",
      "1259   23   1  8.590244  \n",
      "264    45   2  8.850217  \n",
      "147   350   2  9.000000  \n",
      "1463   44   1  9.000000  \n"
     ]
    }
   ],
   "source": [
    "print(worst_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     uid     iid  rui       est                                   details  Iu  \\\n",
      "50    10   76046  1.0  5.006977                 {'was_impossible': False}  17   \n",
      "206   10  217627  9.0  5.006977                 {'was_impossible': False}  17   \n",
      "309   10  197578  2.0  5.006977                 {'was_impossible': False}  17   \n",
      "882   10   57057  2.0  5.057548  {'actual_k': 0, 'was_impossible': False}  17   \n",
      "1099  10     767  1.0  5.006977                 {'was_impossible': False}  17   \n",
      "\n",
      "      Ui       err  \n",
      "50     0  4.006977  \n",
      "206    0  3.993023  \n",
      "309    0  3.006977  \n",
      "882    1  3.057548  \n",
      "1099   0  4.006977  \n"
     ]
    }
   ],
   "source": [
    "#  selecting predictions for the 10th user\n",
    "df_filtered = df[df['uid'] == \"10\"]\n",
    "print(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Singular Value Decomposition algorithm showed good performance together with KNNBaseline, I will tune the SVD as it may help to improve accuracy. I am going to use GridSearchCV method to evaluate the performance of the SVD algorithm on various combinations of parameters and extract the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building SVD model\n",
    "algo = SVD(random_state=10)\n",
    "algo.fit(trainSet)\n",
    "#  making predictions\n",
    "predictions = algo.test(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.9199\n",
      "MAE:  2.4748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.4747733928955222"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing model accuracy\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning SVD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score attained:  2.8631928404173324\n",
      "{'n_epochs': 30, 'lr_all': 0.01, 'n_factors': 50}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# dictionary with algorithm parameters as keys and list of values as keys.\n",
    "param_grid = {'n_epochs': [20, 30], 'lr_all': [0.005, 0.010],\n",
    "              'n_factors': [50, 100]}\n",
    "# running GridSearchCV method and selecting best parameters based on lowest RMSE\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(\"Best RMSE score attained: \", gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])\n",
    "params = gs.best_params['rmse']\n",
    "\n",
    "# applying selected best parameters to build a new algorithm\n",
    "SVDtuned = SVD(n_epochs = params['n_epochs'], lr_all = params['lr_all'], n_factors = params['n_factors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.9116\n",
      "MAE:  2.4696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.469604738610574"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  making predictions\n",
    "SVDtuned.fit(trainSet)\n",
    "predictions_SVDtuned = SVDtuned.test(testSet)\n",
    "# computing model accuracy\n",
    "accuracy.rmse(predictions_SVDtuned)\n",
    "accuracy.mae(predictions_SVDtuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see just tuning the parameters we can achieve higher accuracy results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Covarage and Diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommendations that are most accurate according to the standard metrics are sometimes not the recommendations that are most useful to users. Some studies are argue that one of the goals of recommender systems is to provide a user with personalized items and more diverse recommendations result in more opportunities for users to get recommended such items and utilize “long-tail” area. \n",
    "\n",
    "Diversity\n",
    "\n",
    "Having diverse recommendations is important as it helps to avoid the popularity bias. There is a trade off between accuracy and diversity. We can consider diversity of the recommendations as 1 - total similarity between candidates. \n",
    "\n",
    "Coverage\n",
    "\n",
    "Coverage is the % of the possible recommendations that the system is able to provide. A lot of candidates in the system do not have ratings yet. Coverage gives a sense of how quickly new candidates start to appear in recommendations. \n",
    "\n",
    "I will calculate coverage and diversity of the KNN Baseline recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x10237ec88>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting similarity options\n",
    "sim_options = {'name': 'pearson_baseline', 'user_based': False}\n",
    "# fitting the algorithm to the whole dataset, rather than running cross-validation\n",
    "fullTrainSet = data.build_full_trainset()\n",
    "#  running KNNBaseline algorithm on the fullTrainSet\n",
    "simsAlgo = KNNBaseline(sim_options=sim_options)\n",
    "simsAlgo.fit(fullTrainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  code is taken from \"surprise\" package documentation\n",
    "def get_top_n(predictions, n=10):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  predict ratings for all pairs (u, i) that are NOT in the training set.\n",
    "algo.fit(fullTrainSet)\n",
    "bigTestSet = fullTrainSet.build_anti_testset()\n",
    "allPredictions = algo.test(bigTestSet)\n",
    "#  making top 10 predictions for each user\n",
    "top_n = get_top_n(allPredictions, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating coverage...\n",
      "0.053\n"
     ]
    }
   ],
   "source": [
    "# What percentage of users have at least one \"good\" recommendation. I consider \"good\" recommendation with rating 8 and above\n",
    "def UserCoverage(topNPredicted, numUsers, ratingThreshold=8):\n",
    "    hits = 0\n",
    "    for userID in topNPredicted.keys():\n",
    "        hit = False\n",
    "        for candidateID, predictedRating in topNPredicted[userID]:\n",
    "            if (predictedRating >= ratingThreshold):\n",
    "                hit = True\n",
    "                break\n",
    "        if (hit):\n",
    "            hits += 1\n",
    "\n",
    "    return hits / numUsers\n",
    "\n",
    "\n",
    "\n",
    "coverage = UserCoverage(top_n, 1000)\n",
    "\n",
    "print(\"calculating coverage...\")\n",
    "print(coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating diversity...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "0.9960051148112716\n"
     ]
    }
   ],
   "source": [
    " # diversity\n",
    "\n",
    "def Diversity(topNPredicted, simsAlgo):\n",
    "    n = 0\n",
    "    total = 0\n",
    "#     building the similarity matrix, only relevant for the k-NN algorithms.\n",
    "    simsMatrix = simsAlgo.compute_similarities()\n",
    "    for userID in topNPredicted.keys():\n",
    "#          producing an iterator over the tuples of topNPredicted userIDs\n",
    "        pairs = itertools.combinations(topNPredicted[userID], 2)\n",
    "        for pair in pairs:\n",
    "            candidate1 = pair[0][0]\n",
    "            candidate2 = pair[1][0]\n",
    "#           converting raw IDs to inner IDs\n",
    "            innerID1 = simsAlgo.trainset.to_inner_iid(str(candidate1))\n",
    "            innerID2 = simsAlgo.trainset.to_inner_iid(str(candidate2))\n",
    "            similarity = simsMatrix[innerID1][innerID2]\n",
    "#             calculating total similarity as a sum of all possible pair similarities\n",
    "            total += similarity\n",
    "            n += 1\n",
    "#  calculating total diversity as 1 - total similarity\n",
    "    S = total / n\n",
    "    return (1 - S)\n",
    "\n",
    "\n",
    "print(\"calculating diversity...\")\n",
    "print(Diversity(top_n,simsAlgo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final project various methods of building recommender system were tested and assessed. The implementation was started from the simple user- and item- based collaborative filtering methods and then I have dived dipper into KNN methods which allow to predict candidates ratings and build user- and item-based collaborative filtering based on the predicted ratings. Matrix factorization techniques such as SVD method was implemented and tuned in order to get more accurate results.\n",
    "\n",
    "Accuracy is not everything. The recommendations that are most accurate according to the standard metrics are sometimes not the recommendations that are most useful to users. Coverage and Diversity were calculated and implemented as possible types of user satisfaction measures.\n",
    "\n",
    "Although simple user- and item-based collaborative filtering does not allow me to calculate accuracy as it is just top N recommender and it does not predict rating. In this case it is hard to evaluate the user- and item-based collaborative filtering without running the experiments on the real world users.\n",
    "\n",
    "The KNN algorithms are more complex, but unfortunately do not work well in practice as it force collaborative filtering to make predictions on ratings, which are in not continuous by nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "\n",
    "https://surprise.readthedocs.io/en/stable/FAQ.html\n",
    "\n",
    "https://kerpanic.wordpress.com/2018/03/26/a-gentle-guide-to-recommender-systems-with-surprise/\n",
    "\n",
    "https://towardsdatascience.com/building-and-testing-recommender-systems-with-surprise-step-by-step-d4ba702ef80b\n",
    "\n",
    "http://www.occamslab.com/petricek/papers/dating/brozovsky07recommender.pdf\n",
    "\n",
    "https://buildmedia.readthedocs.org/media/pdf/surprise/stable/surprise.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
