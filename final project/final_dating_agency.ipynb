{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System For Dating Agency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users of online dating sites are facing information overload that requires them to manually construct queries and browse huge amount of matching user profiles. A typical dating site requires users to fill in lengthy questionnaires and matching is based on attributes selected. The search in the database either returns no match in the case when the query is too specific or, for general queries, returns a huge amount of profiles. In the end users end up browsing large amount of irrelevant results. Building a recommender system can help to improve user experience of dating site users and lead to a higher user satisfaction by making the process of finding a relevant candidate quicker and more efficient.\n",
    "\n",
    "The purpose of this project is to develop a recommender system using collaborative filtering algorithms (user- and item-based) walking though the following steps:\n",
    "\n",
    "1. Data Exploration\n",
    "2. User-Based Collaborative Filtering (top N recommendations)\n",
    "3. Item-Based Collaborative Filtering (top N recommendations)\n",
    "4. KNN Recommender Algorithms. Selecting the best system based on the RMSE using cross validation.\n",
    "5. Measuring Coverage and Diversity of the selected KNN-Recommender Algorithm.\n",
    "6. Implementation SVD method and tuning it selecting best parameter using RMSE.\n",
    "\n",
    "Core ML package that will be used throughout the project is Surprise - Python scikit building and analyzing recommender systems library.\n",
    "\n",
    "Data Source: http://www.occamslab.com/petricek/data/\n",
    "\n",
    "This data set contains 168,791 profiles and presented in the following format:\n",
    "\n",
    "UserID is user who provided rating\n",
    "\n",
    "ProfileID is user who has been rated\n",
    "\n",
    "UserIDs range between 1 and 135,359\n",
    "\n",
    "ProfileIDs range between 1 and 220,970 (not every profile has been rated)\n",
    "\n",
    "Ratings are on a 1-10 scale where 10 is best (integer ratings only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import KNNBaseline, KNNWithZScore, NormalPredictor, KNNWithMeans, BaselineOnly, SVD, KNNBasic, SlopeOne, NMF, CoClustering\n",
    "\n",
    "# import heapq\n",
    "import random \n",
    "import numpy as np\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>candidateID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>971</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1095</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1616</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  candidateID  rating\n",
       "0       1          133       8\n",
       "1       1          720       6\n",
       "2       1          971      10\n",
       "3       1         1095       7\n",
       "4       1         1616      10"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading file into a pandas data frame from the source. File is to big to push it to GitHub, even zip version\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/olgashiligin/DATA_612/master/final%20project/ratings_1000.csv\", header=None)\n",
    "data.columns = [\"userID\", \"candidateID\", \"rating\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    28885\n",
       "9      9459\n",
       "8     13771\n",
       "7     14890\n",
       "6     13133\n",
       "5     16786\n",
       "4      9502\n",
       "3      8583\n",
       "2     10787\n",
       "1     20752\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  rating distribution\n",
    "data.rating.value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rating distribution (graph)\n",
    "data.rating.value_counts().sort_index(ascending=False).plot(kind='bar')\n",
    "plt.title('Rating Distribution')\n",
    "plt.ylabel('Number Of Users')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 is the most popular rating. 1 and 5 are also polular ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidateID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33899</th>\n",
       "      <td>156148</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6711</th>\n",
       "      <td>31116</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26648</th>\n",
       "      <td>121859</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41569</th>\n",
       "      <td>193687</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18350</th>\n",
       "      <td>83773</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19668</th>\n",
       "      <td>89855</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15666</th>\n",
       "      <td>71636</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>22319</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4410</th>\n",
       "      <td>20737</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7166</th>\n",
       "      <td>33216</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       candidateID  rating\n",
       "33899       156148     240\n",
       "6711         31116     218\n",
       "26648       121859     182\n",
       "41569       193687     169\n",
       "18350        83773     159\n",
       "19668        89855     151\n",
       "15666        71636     148\n",
       "4743         22319     140\n",
       "4410         20737     138\n",
       "7166         33216     138"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of ratings per each candidate\n",
    "data.groupby('candidateID')['rating'].count().reset_index().sort_values('rating', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-Based and Item-Based (top N recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first algorithm that will be built is user-based collaborative filtering. I will take the \"test user\" (for example,10th user) and find the top 10 candidates for the \"test user\" via following steps:\n",
    "\n",
    "1. Candidate generation step when we pull all the candidates in from every neighbor of the selected \"test user\". Neighbours for the \"test user\" is selected based on the similarity measure.\n",
    "\n",
    "2. Candidate scoring allows to select the best candidates for the \"test user\". I will weigh ratings by users similarity.\n",
    "\n",
    "3. Sorting the candidates by their final score.\n",
    "\n",
    "4. Candidates filtering where I filter out candidates which the \"test user\" has already rated. Also I will apply filter on the min candidate score or min similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading csv file\n",
    "reader = Reader(sep=',', rating_scale=(1, 10))\n",
    "data = Dataset.load_from_file(\"/Users/Olga/PycharmProjects/rec_sys_final/ratings_1000.csv\", reader=reader)\n",
    "# splitting data set on train and test\n",
    "trainSet, testSet = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "#  assigning similarity measure options\n",
    "sim_options = {'name': 'cosine', 'user_based': True}\n",
    "\n",
    "#  computing user to user similarity matrix using KNNBasic algorithm\n",
    "model = KNNBasic(sim_options = sim_options)\n",
    "model.fit(trainSet)\n",
    "simMatrix = model.compute_similarities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33216 45.154194077439186\n",
      "22319 38.02369596596644\n",
      "113157 36.86256298243028\n",
      "71570 28.898251052139255\n",
      "81470 24.77152711555244\n",
      "97992 18.711020415926267\n",
      "22327 18.6\n",
      "73728 17.21974592397711\n",
      "74257 17.116045795877078\n",
      "25978 16.44537607994736\n"
     ]
    }
   ],
   "source": [
    "# selecting test user - for example, 10th user\n",
    "testUser = '10'\n",
    "\n",
    "# extracting similar users to our test user\n",
    "testUserInnerID = trainSet.to_inner_uid(testUser)\n",
    "similarityRow = simMatrix[testUserInnerID]\n",
    "\n",
    "# converting these users to the list of tuples containing inner user Id and similarity score (skipping the test user similarity to him/herself)\n",
    "similarUsers = []\n",
    "for innerID, score in enumerate(similarityRow):\n",
    "    if (innerID != testUserInnerID):\n",
    "        similarUsers.append( (innerID, score) )\n",
    "        \n",
    "#  filtering out users with similarity score to the test user less than 0.95   \n",
    "kNeighbors = []\n",
    "for rating in similarUsers:\n",
    "    if rating[1] > 0.95:\n",
    "        kNeighbors.append(rating)\n",
    "\n",
    "# getting the candidates the users have rated, and adding up ratings for each candidate, weighted by user similarity\n",
    "candidates = defaultdict(float)\n",
    "for similarUser in kNeighbors:\n",
    "    innerID = similarUser[0]\n",
    "    userSimilarityScore = similarUser[1]\n",
    "    theirRatings = trainSet.ur[innerID]\n",
    "    for rating in theirRatings:\n",
    "        candidates[rating[0]] += (rating[1]/10.0) * userSimilarityScore\n",
    "\n",
    "# Building a dictionary of candidates that the test user has already rated\n",
    "rated = {}\n",
    "for candidateID, rating in trainSet.ur[testUserInnerID]:\n",
    "    rated[candidateID] = 1\n",
    "\n",
    "# getting 10 top-rated candidates for the test user:\n",
    "n = 10\n",
    "pos = 1\n",
    "# sorting the candidates by the final score and selecting top 10 skipping the results that the test user has already rated.\n",
    "for candidateID, ratingSum in sorted(candidates.items(), key=itemgetter(1), reverse=True):\n",
    "    if not candidateID in rated:\n",
    "        candidateID = trainSet.to_raw_iid(candidateID)\n",
    "#       printing candidates IDs for 10th test user \n",
    "        print(candidateID, ratingSum)\n",
    "        pos += 1\n",
    "        if (pos > n):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Next algorithm that I am going to implement is item-based. I will take the same \"test user\" (10th user) and find the top 10 candidates for the \"test user\" using item-based collaborative filtering.\n",
    "Item similarities can be better then similarities between users because items tend to have more permanent nature, unlike users' tastes. That's why focusing on the similarities between unchanging objects may produce better results.\n",
    "The algorithms for item-based recommendations is quite similar to user - based, we are just focusing on the relations between items instead of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "#  assigning similarity measure options\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': False\n",
    "               }\n",
    "\n",
    "#  computing candidate to candidate similarity matrix \n",
    "model = KNNBasic(sim_options=sim_options)\n",
    "model.fit(trainSet)\n",
    "simsMatrix = model.compute_similarities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113666 2.8\n",
      "110424 2.8\n",
      "109899 2.8\n",
      "200492 2.798446935857496\n",
      "9652 2.788986668796162\n",
      "77036 2.773687418864638\n",
      "71570 2.771559411588529\n",
      "22319 2.756795134263671\n",
      "125439 2.7461785443066185\n",
      "82986 2.7405691595989397\n"
     ]
    }
   ],
   "source": [
    "# selecting test user - for example, 10th user\n",
    "testUser = '10'\n",
    "\n",
    "# converting a user raw id to an inner id\n",
    "testUserInnerID = trainSet.to_inner_uid(testUser)\n",
    "# extracting similar candidates to the candidates the test user prefer\n",
    "testUserRatings = trainSet.ur[testUserInnerID]\n",
    "\n",
    "# filtering out candidates with rating less then 8\n",
    "kNeighbors = []\n",
    "for rating in testUserRatings:\n",
    "    if rating[1] > 8.0:\n",
    "        kNeighbors.append(rating)\n",
    "        \n",
    "\n",
    "# getting the candidates and adding up ratings for each candidate, weighted by similarity score\n",
    "candidates = defaultdict(float)\n",
    "for candidateID, rating in kNeighbors:\n",
    "    similarityRow = simsMatrix[candidateID]\n",
    "    for innerID, score in enumerate(similarityRow):\n",
    "        candidates[innerID] += score * (rating)/10.0\n",
    "    \n",
    "# building a dictionary of candidates that the test user has already seen\n",
    "rated = {}\n",
    "for candidateID, rating in trainSet.ur[testUserInnerID]:\n",
    "    rated[candidateID] = 1\n",
    "    \n",
    "# getting 10 top-rated candidated for the test user:\n",
    "n = 10\n",
    "pos = 1\n",
    "for candidateID, ratingSum in sorted(candidates.items(), key=itemgetter(1), reverse=True):\n",
    "    if not candidateID in rated:\n",
    "        candidateID = trainSet.to_raw_iid(candidateID)\n",
    "        print(candidateID, ratingSum)\n",
    "        pos += 1\n",
    "        if (pos > n):\n",
    "            break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User-based and item-based algorithms produced quite different recommendations: only 2 out of 10 recommendations are similar for the 10th user. It is hard to tell if they are good or bad. I can not measure accuracy for the simple ser-/item-based algorithms produced above as they are not rating prediction methods which I will consider further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Recommender Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept of collaborative filtering has been applied to recommender systems that make rating predictions and this is called KNN recommenders.\n",
    "In KNN recommender systems we are generating recommendation candidates by predicting their rating and selecting top K candidates with the highest predicted rating. Since we are using ratings prediction we can measure system accuracy via train/test split or cross-validation. \n",
    "\n",
    "KNN recommenders are not just recommending candidates that people similar to the selected user like, but also they are trying to predict rating for every possible candidate for every possible user. \n",
    "\n",
    "The following basics algorithms will be benchmarked in order to select the best one:\n",
    "\n",
    "    - NormalPredictor algorithm predicts a random rating based on the distribution of the training set, which is assumed to be normal.\n",
    "    - KNNBaseline is a basic collaborative filtering algorithm taking into account a baseline rating.\n",
    "    - KNNBasic is a basic collaborative filtering algorithm.\n",
    "    - KNNWithMeans is basic collaborative filtering algorithm, taking into account the mean ratings of each user.\n",
    "    - KNNWithZScore is a basic collaborative filtering algorithm, taking into account the z-score normalization of each user.\n",
    "    - BaselineOnly is a basic collaborative filtering algorithm taking into account a baseline rating.\n",
    "    - SVD is a method that utilizes matrix factorization technique.\n",
    "    \n",
    "Some of these algorithms use baseline estimates, some use a similarity measures.  \n",
    "These algorithms will be tested using user- and item-based approach with cosine or pearson similarity measure. Cross-validation will be applied to measure algorithms accuracy via RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>2.374041</td>\n",
       "      <td>0.616729</td>\n",
       "      <td>1.436186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>2.465770</td>\n",
       "      <td>0.276004</td>\n",
       "      <td>1.066208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>2.475599</td>\n",
       "      <td>0.339966</td>\n",
       "      <td>1.224553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>2.480321</td>\n",
       "      <td>6.246900</td>\n",
       "      <td>0.488930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>2.521116</td>\n",
       "      <td>0.369429</td>\n",
       "      <td>0.328299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>2.582169</td>\n",
       "      <td>0.247367</td>\n",
       "      <td>1.111087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>4.131257</td>\n",
       "      <td>0.156038</td>\n",
       "      <td>0.369851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_rmse  fit_time  test_time\n",
       "Algorithm                                      \n",
       "KNNBaseline       2.374041  0.616729   1.436186\n",
       "KNNWithMeans      2.465770  0.276004   1.066208\n",
       "KNNWithZScore     2.475599  0.339966   1.224553\n",
       "SVD               2.480321  6.246900   0.488930\n",
       "BaselineOnly      2.521116  0.369429   0.328299\n",
       "KNNBasic          2.582169  0.247367   1.111087\n",
       "NormalPredictor   4.131257  0.156038   0.369851"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark = []\n",
    "sim_options = {'name': 'cosine', 'user_based': True}\n",
    "# iterating over all algorithms\n",
    "for algorithm in [SVD(), NormalPredictor(), KNNBaseline(sim_options=sim_options), KNNBasic(sim_options=sim_options), KNNWithMeans(sim_options=sim_options), KNNWithZScore(sim_options=sim_options), BaselineOnly()]:\n",
    "    # performing 3 fold cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "    \n",
    "    # getting results & appending algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    \n",
    "pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>2.390775</td>\n",
       "      <td>0.676031</td>\n",
       "      <td>1.224962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>2.482256</td>\n",
       "      <td>6.440402</td>\n",
       "      <td>0.498487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>2.487862</td>\n",
       "      <td>0.439788</td>\n",
       "      <td>1.259079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>2.489275</td>\n",
       "      <td>0.368903</td>\n",
       "      <td>1.107933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>2.521466</td>\n",
       "      <td>0.392932</td>\n",
       "      <td>0.339808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>2.600046</td>\n",
       "      <td>0.329244</td>\n",
       "      <td>1.081094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>4.139537</td>\n",
       "      <td>0.161848</td>\n",
       "      <td>0.412155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_rmse  fit_time  test_time\n",
       "Algorithm                                      \n",
       "KNNBaseline       2.390775  0.676031   1.224962\n",
       "SVD               2.482256  6.440402   0.498487\n",
       "KNNWithZScore     2.487862  0.439788   1.259079\n",
       "KNNWithMeans      2.489275  0.368903   1.107933\n",
       "BaselineOnly      2.521466  0.392932   0.339808\n",
       "KNNBasic          2.600046  0.329244   1.081094\n",
       "NormalPredictor   4.139537  0.161848   0.412155"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark = []\n",
    "sim_options = {'name': 'pearson', 'user_based': True}\n",
    "# iterating over all algorithms\n",
    "for algorithm in [SVD(), NormalPredictor(), KNNBaseline(sim_options=sim_options), KNNBasic(sim_options=sim_options), KNNWithMeans(sim_options=sim_options), KNNWithZScore(sim_options=sim_options), BaselineOnly()]:\n",
    "    # performing 3 fold cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "    \n",
    "    # getting results & appending algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    \n",
    "pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most accurate result produces KNNBaseline, the worst - NormalPredictor, although it is the fastest algorithm. I am going to train and predict with KNNBaseline method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 2.3180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.318025404185668"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  splitting data on train and test set\n",
    "trainSet, testSet = train_test_split(data, test_size=.15)\n",
    "# selecting similarity options which gave the best result during cross-validation: user-based and pearson.\n",
    "sim_options = {'name': 'pearson', 'user_based': True}\n",
    "#  building the model\n",
    "algo = KNNBaseline(sim_options = sim_options)\n",
    "model = algo.fit(trainSet)\n",
    "#  making predictions\n",
    "predictions = model.test(testSet)\n",
    "# calculating RMSE\n",
    "accuracy.rmse(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://nbviewer.jupyter.org/github/NicolasHug/Surprise/blob/master/examples/notebooks/KNNBasic_analysis.ipynb\n",
    "# selecting top 10 best and worst predictions.\n",
    "def get_Iu(uid):\n",
    "    \"\"\" return the number of items rated by given user\n",
    "    args: \n",
    "      uid: the id of the user\n",
    "    returns: \n",
    "      the number of items rated by the user\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return len(trainSet.ur[trainSet.to_inner_uid(uid)])\n",
    "    except ValueError: # user was not part of the trainSet\n",
    "        return 0\n",
    "    \n",
    "def get_Ui(iid):\n",
    "    \"\"\" return number of users that have rated given item\n",
    "    args:\n",
    "      iid: the raw id of the item\n",
    "    returns:\n",
    "      the number of users that have rated the item.\n",
    "    \"\"\"\n",
    "    try: \n",
    "        return len(trainSet.ir[trainSet.to_inner_iid(iid)])\n",
    "    except ValueError:\n",
    "        return 0\n",
    "    \n",
    "df = pd.DataFrame(predictions, columns=['uid', 'iid', 'rui', 'est', 'details'])\n",
    "df['Iu'] = df.uid.apply(get_Iu)\n",
    "df['Ui'] = df.iid.apply(get_Ui)\n",
    "df['err'] = abs(df.est - df.rui)\n",
    "best_predictions = df.sort_values(by='err')[:10]\n",
    "worst_predictions = df.sort_values(by='err')[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       uid     iid   rui   est                                    details  \\\n",
      "21982  712  214534   1.0   1.0   {'actual_k': 1, 'was_impossible': False}   \n",
      "11551  572   30031   1.0   1.0  {'actual_k': 10, 'was_impossible': False}   \n",
      "11583  348  144691   1.0   1.0   {'actual_k': 6, 'was_impossible': False}   \n",
      "11584   31   79138  10.0  10.0   {'actual_k': 7, 'was_impossible': False}   \n",
      "11588  956    9759  10.0  10.0  {'actual_k': 13, 'was_impossible': False}   \n",
      "11593  284   83846  10.0  10.0  {'actual_k': 14, 'was_impossible': False}   \n",
      "11681  855   69366  10.0  10.0   {'actual_k': 5, 'was_impossible': False}   \n",
      "11685  783   66986  10.0  10.0   {'actual_k': 1, 'was_impossible': False}   \n",
      "11717  720  132688  10.0  10.0  {'actual_k': 15, 'was_impossible': False}   \n",
      "1904   805  139250  10.0  10.0   {'actual_k': 2, 'was_impossible': False}   \n",
      "\n",
      "         Iu  Ui  err  \n",
      "21982   154   1  0.0  \n",
      "11551   163  13  0.0  \n",
      "11583   507   6  0.0  \n",
      "11584   349   7  0.0  \n",
      "11588   264  15  0.0  \n",
      "11593    81  16  0.0  \n",
      "11681   105  19  0.0  \n",
      "11685   145   5  0.0  \n",
      "11717  2487  15  0.0  \n",
      "1904     64   3  0.0  \n"
     ]
    }
   ],
   "source": [
    "print(best_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       uid     iid   rui   est                                   details  \\\n",
      "19138  879   51214  10.0   1.0  {'actual_k': 1, 'was_impossible': False}   \n",
      "21328  251  188712  10.0   1.0  {'actual_k': 1, 'was_impossible': False}   \n",
      "19131  194  186880  10.0   1.0  {'actual_k': 1, 'was_impossible': False}   \n",
      "1407   783  182016   1.0  10.0  {'actual_k': 2, 'was_impossible': False}   \n",
      "6514   248   73971  10.0   1.0  {'actual_k': 1, 'was_impossible': False}   \n",
      "711    730  131978  10.0   1.0  {'actual_k': 1, 'was_impossible': False}   \n",
      "18227   35  129599   1.0  10.0  {'actual_k': 2, 'was_impossible': False}   \n",
      "4202   348  184479   1.0  10.0  {'actual_k': 1, 'was_impossible': False}   \n",
      "507    757   66102   1.0  10.0  {'actual_k': 1, 'was_impossible': False}   \n",
      "1990     9   93420   1.0  10.0  {'actual_k': 1, 'was_impossible': False}   \n",
      "\n",
      "         Iu  Ui  err  \n",
      "19138  1555   1  9.0  \n",
      "21328  2308   1  9.0  \n",
      "19131    56   1  9.0  \n",
      "1407    145   5  9.0  \n",
      "6514    396   1  9.0  \n",
      "711    1432   1  9.0  \n",
      "18227   147   2  9.0  \n",
      "4202    507   1  9.0  \n",
      "507    2163   1  9.0  \n",
      "1990   2986   1  9.0  \n"
     ]
    }
   ],
   "source": [
    "print(worst_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      uid     iid  rui       est                                   details  \\\n",
      "18303  10  116015  5.0  5.171557  {'actual_k': 5, 'was_impossible': False}   \n",
      "\n",
      "       Iu  Ui       err  \n",
      "18303  21   7  0.171557  \n"
     ]
    }
   ],
   "source": [
    "#  selecting predictions for the 10th user\n",
    "df_filtered = df[df['uid'] == \"10\"]\n",
    "print(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Singular Value Decomposition algorithm showed good performance together with KNNBaseline, I will tune the SVD as it may help to improve accuracy. I am going to use GridSearchCV method to evaluate the performance of the SVD algorithm on various combinations of parameters and extract the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building SVD model\n",
    "algo = SVD(random_state=10)\n",
    "algo.fit(trainSet)\n",
    "#  making predictions\n",
    "predictions = algo.test(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.3874\n",
      "MAE:  1.9027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.902654228621037"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing model accuracy\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning SVD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score attained:  2.4381329819636353\n",
      "{'n_epochs': 30, 'lr_all': 0.01, 'n_factors': 50}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# dictionary with algorithm parameters as keys and list of values as keys.\n",
    "# 'lr_all' - learning rate\n",
    "# 'n_epochs' - number of steps to take\n",
    "# 'n_factors' - number of factors\n",
    "param_grid = {'n_epochs': [20, 30], 'lr_all': [0.005, 0.010],\n",
    "              'n_factors': [50, 100]}\n",
    "# running GridSearchCV method and selecting best parameters based on lowest RMSE\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(\"Best RMSE score attained: \", gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])\n",
    "params = gs.best_params['rmse']\n",
    "\n",
    "# applying selected best parameters to build a new algorithm\n",
    "SVDtuned = SVD(n_epochs = params['n_epochs'], lr_all = params['lr_all'], n_factors = params['n_factors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.3556\n",
      "MAE:  1.8568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.8567869323403596"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  making predictions\n",
    "SVDtuned.fit(trainSet)\n",
    "predictions_SVDtuned = SVDtuned.test(testSet)\n",
    "# computing model accuracy\n",
    "accuracy.rmse(predictions_SVDtuned)\n",
    "accuracy.mae(predictions_SVDtuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see just tuning the parameters we can achieve higher accuracy results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Covarage and Diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommendations that are most accurate according to the standard metrics are sometimes not the recommendations that are most useful to users. Some studies are argue that one of the goals of recommender systems is to provide a user with personalized items and more diverse recommendations result in more opportunities for users to get recommended such items and utilize long-tail area. \n",
    "\n",
    "Diversity\n",
    "\n",
    "Having diverse recommendations is important as it helps to avoid the popularity bias. There is a trade off between accuracy and diversity. We can consider diversity of the recommendations as 1 - total similarity between candidates. \n",
    "\n",
    "Coverage\n",
    "\n",
    "Coverage is the % of the possible recommendations that the system is able to provide. A lot of candidates in the system do not have ratings yet. Coverage gives a sense of how quickly new candidates start to appear in recommendations. \n",
    "\n",
    "I will calculate coverage and diversity of the KNN Baseline recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting similarity options\n",
    "sim_options = {'name': 'pearson_baseline', 'user_based': True}\n",
    "# fitting the algorithm to the whole dataset, rather than running cross-validation\n",
    "fullTrainSet = data.build_full_trainset()\n",
    "#  running KNNBaseline algorithm on the fullTrainSet\n",
    "simsAlgo = KNNBaseline(sim_options=sim_options)\n",
    "simsAlgo.fit(fullTrainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  code is taken from \"surprise\" package documentation\n",
    "def get_top_n(predictions, n=10):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  predict ratings for all pairs (u, i) that are NOT in the training set.\n",
    "algo.fit(fullTrainSet)\n",
    "bigTestSet = fullTrainSet.build_anti_testset()\n",
    "allPredictions = algo.test(bigTestSet)\n",
    "#  making top 10 predictions for each user\n",
    "top_n = get_top_n(allPredictions, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating coverage...\n",
      "0.997\n"
     ]
    }
   ],
   "source": [
    "# What percentage of users have at least one \"good\" recommendation. I consider \"good\" recommendation with rating 8 and above\n",
    "def UserCoverage(topNPredicted, numUsers, ratingThreshold=8):\n",
    "    hits = 0\n",
    "    for userID in topNPredicted.keys():\n",
    "        hit = False\n",
    "        for candidateID, predictedRating in topNPredicted[userID]:\n",
    "            if (predictedRating >= ratingThreshold):\n",
    "                hit = True\n",
    "                break\n",
    "        if (hit):\n",
    "            hits += 1\n",
    "\n",
    "    return hits / numUsers\n",
    "\n",
    "\n",
    "\n",
    "coverage = UserCoverage(top_n, 1000)\n",
    "\n",
    "print(\"calculating coverage...\")\n",
    "print(coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating diversity...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "0.9499508975124918\n"
     ]
    }
   ],
   "source": [
    " # diversity\n",
    "\n",
    "def Diversity(topNPredicted, simsAlgo):\n",
    "    n = 0\n",
    "    total = 0\n",
    "#     building the similarity matrix, only relevant for the k-NN algorithms.\n",
    "    simsMatrix = simsAlgo.compute_similarities()\n",
    "    for userID in topNPredicted.keys():\n",
    "#          producing an iterator over the tuples of topNPredicted userIDs\n",
    "        pairs = itertools.combinations(topNPredicted[userID], 2)\n",
    "        for pair in pairs:\n",
    "            candidate1 = pair[0][0]\n",
    "            candidate2 = pair[1][0]\n",
    "#           converting raw IDs to inner IDs\n",
    "            innerID1 = simsAlgo.trainset.to_inner_iid(str(candidate1))\n",
    "            innerID2 = simsAlgo.trainset.to_inner_iid(str(candidate2))\n",
    "            similarity = simsMatrix[innerID1][innerID2]\n",
    "#             calculating total similarity as a sum of all possible pair similarities\n",
    "            total += similarity\n",
    "            n += 1\n",
    "#  calculating total diversity as 1 - total similarity\n",
    "    S = total / n\n",
    "    return (1 - S)\n",
    "\n",
    "\n",
    "print(\"calculating diversity...\")\n",
    "print(Diversity(top_n,simsAlgo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coverage looks high,which is good, but I have applied the algorithm only to the 1000 users. For the full set it is expected to be lower. Diversity looks quite high, but it is hard to judge in isolation with other metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final project various methods of building recommender system were tested and assessed. The implementation was started from the simple user- and item- based collaborative filtering methods and then I have dived dipper into KNN methods which allow to predict candidates ratings and build user- and item-based collaborative filtering based on the predicted ratings. Matrix factorization techniques such as SVD method was implemented and tuned in order to get more accurate results.\n",
    "\n",
    "Accuracy is not everything. The recommendations that are most accurate according to the standard metrics are sometimes not the recommendations that are most useful to users. Coverage and Diversity were calculated and implemented as possible types of user satisfaction measures.\n",
    "\n",
    "Although simple user- and item-based collaborative filtering does not allow me to calculate accuracy as it is just top N recommender and it does not predict rating. In this case it is hard to evaluate the user- and item-based collaborative filtering without running the experiments on the real world users.\n",
    "\n",
    "The KNN algorithms are more complex, but unfortunately do not work well in practice as it force collaborative filtering to make predictions on ratings, which are in not continuous by nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "\n",
    "https://surprise.readthedocs.io/en/stable/FAQ.html\n",
    "\n",
    "https://kerpanic.wordpress.com/2018/03/26/a-gentle-guide-to-recommender-systems-with-surprise/\n",
    "\n",
    "https://towardsdatascience.com/building-and-testing-recommender-systems-with-surprise-step-by-step-d4ba702ef80b\n",
    "\n",
    "http://www.occamslab.com/petricek/papers/dating/brozovsky07recommender.pdf\n",
    "\n",
    "https://buildmedia.readthedocs.org/media/pdf/surprise/stable/surprise.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
